= Proposed ideas for the SoC 2007 =

== Plugin system for a dynamically extensible framework ==
more here: [[Devel/Plugins TODOs]]

* CLAM network as plugins host
** Multi-platform dynamic loading of factories.
** Hierarchical organization
** Documentation and plugin metadata (ports meta-data, etc)
** Loading Ladspa plugins
** Loading VST plugins
* Using CLAM as plugin creation toolkit
** Load CLAM networks as ladspa plugins
** Load CLAM networks as vst plugins

== Network Scalability (aka Subnetworks) ==
* Infrastructure to control the flow of recursive networks
* Integrate user-defined networks in the component library.
* Make it usable in NetworkEditor application.
* ...

== Processing Editor ==

* Defining a new processing just by defining the ports and the code in the Do method
* The system will compile it and will add it to the user's plugin library
* It would be great to have it integrated on the NetworkEditor
* This project could be related to the Python scripting project but we are considering C++ code here.

== Scripting CLAM in Python ==

* several approaches: Adhoc API or API export using SWIG or SIP
* build and use a clam network with python
* this could lead to a NetworkEditor python console with tab-completion
* use clam processings and processing-data with python. use it to visualize data, etc.
* write clam processings with python
** Related to the 'Processing editor' project
* Network scoring
** Sequencing changes on a network along the time
** Configurations, connections, control sending...

== Improve usability of SMSTools workflow ==

* Remove the files to process from the configuration and use configuration as presets
* Data to open are just audio or analysis data
* Object centric interaction: you apply an action (synthesis, analysis, transform) to an object
* Minimize the provided data by using object information (sampling rate on analysis, and most of the analysis parameters embedded on the object for resynthesis)

== Convergence of SMSTools and CLAM widgets infrastructure ==
* Transformation parameter automation using time-lines (ala ardour automation)
* Metadata based widgets
* Widgets interaction (zoom)
* Network based transformations. The user should be able to define the transformation chain using NetworkEditor.

== Real-time synthesizer using SMS models ==
* a new revamped but very simple salto synthesizer.
* a db of sms samples
* processings 
** to choose samples
** interpolate
** create stream flow
** etc.

== Vowel synthesizer ==

Build a educative program that would consist on:
* synthesizing different vowels by placing a point within the [http://en.wikipedia.org/wiki/Vowel_triangle Vowel triangle],
* and, the reverse, given an input vowel from the microphone place a dot on the triangle, so the students can check their pronunciation.
This could be enhanced by:
* displaying the mouth position for the vowel,
* visualizing the spectral peaks so they can identify the effect,
* changing the pitch,
* changing the synthesized gender,
* changing the vocal track characteristics,
* extracting user's vocal track characteristics for synthesized sound.

A teacher could limit the set of vowels to the ones used for 
a particular language such as Catalan or English,
so that the students just see the relevant ones for the exercise.



== Enhancing chord detection algorithm for real-time use ==

TODO: Adapt scope to SoC requirements

Due to the extend it could be split a subset of the proposals.
It consist on enhancing existing 
tonal analysis algorithms so that they can work reliably on realtime
in order to be exploded by a realtime visualization that could give a
the user some insight on what he is listening.
Although the algorithm may fail to detect the exact chord being played,
visualization should be able to visualize information so that the user
could figure out what's going on.

In order to achive this, two concurrent aspects are to be addressed:
The first one is to modify and enhance existing algorithms
so that they can achieve better results working on realtime.
The second one is to find new ways of representing pitch, tonality and chord information in realtime.

Several algorithm enhancements are to be considered:
* Preprocessing
** Compute instant tunning by fasor addition on chroma peaks mapped to a semitone (done)
** Limit the time scope of the global tunning computation (done but improvements needed)
* Processing
** Find faster and more precise algorithms than the current one	
* Postprocessing
** Consider the None chord (all pitches) so that we can detect non chord segments and use it as reference for pitchness. (done)
** Symbolical analysis: Instead of correlation, analyze the pcp content using heuristic reasoning (Harte did plain filtering and some )
** Double scope for analysis: Too large windows difuminate transitions but small ones fail to detect arpeggios based chords. We could choose depending on the number of high pitches on the PCP.
** Onset alignment: Use realtime onset detection (aubio?) to 'quantize' the chord segments limits.

Enrich algorithm output so that the user may take profit of non-perfect algorithm or music that is not using recognized cords (fifths, rare chords...)
* Diffuse guessing: Minimize false positive impact to the user by computing a confidence value for each guess.
* Keeping several candidates so the user may view that he has more than one option.
* Rectified guess: Do a first realtime guess and correct it later if needed as the song goes on. 

In parallel to enhance the algorithm to realtime some views must be developed.
Some views ideas:
* KeySpace (Emilia and Jordi's) (done)
* Augmented KeySpace (not just major and minor)
* Tonnetz (pcp) (done)
* Tonnetz (pcp + chord figures)
* Chord torus (map pcp into the tonal torus space)
* Vectors in chord torus (needed to disambiguate dim chords)
* Chord ranking: all chords displayed as sorted probability bars (done)
* Chord candidates: just the ones before the first strong decay
* Realtime segment construction:
** Instant chord segment: Display segment based on the best one on each instant.
** Delayed segment: don't display a segment until we have enough information on the future to make a post processing
** Guessed segments: Until sure, display the guess
* Instrument fingering





== Qt based interfaces for CLAM Network based VST plugins ==

Enabling a Qt Designer interface to control a CLAM Network 
run as VST plugin the same way CLAM does now for JACK and PortAudio players.

== Annotation Merger ==

Currently BOCA system does pretty well by defining merges, projections and 
attribute renaming of several annotation sources (extractors, databases,
webservices...).

BOCA merging scripts (developed in python) are distributed with the annotator.
They are useful for example to combine several extractors locally or 
an extractor and a manually annotated ground truth and compare them.
But they are hard to use for a non expert user.

It would be nice to integrate into the annotator a tool to graphically configure 
how to perform such a merge to run it locally.
The idea is that a project could have, instead of a single extractor,
a combination of descriptors sources.

== Macro manipulation of descriptors with python on Annotator ==

Make the annotation data accessible to python scripts
so that one can automate repetitive descriptors manipulation.
Some use cases:
* I want to correct an offset that a given segment annotation adds to all segments.
* I want to extend a regular beat annotation and just correct when it varies

== Enhancing Annotator Widgets ==

TODO: Adapt scope to SoC requirements

* Views for multibin frame parameters (spectrums, pcp's, chord correlation...)
* Frame level float editor
* More instant views
** Spectrum + peaks
** 
* Multiple segmentation panes
* Enhancing the usability of the segment editor
** Selection and edit actions (copy, paste..)
** Overlapping segments
** Displaying segment attributes as height
** Displaying segment attributes as color

== Flexible auralization on Annotator ==

Currently the auralization is limited to some kinds of descriptors auralization.
Currently just playing a tick on segment onset and 
float value frame level descriptors controlling the pitch of a tone.
By adding a general way to convert descriptors to control signals
they can be used to control an arbitrary synthesizer set by the user
(CLAM network? OSC/MIDI controlled synth?)

= Still not included =

== Integrate Faust with CLAM. And spectral transformations with Faust ==


== Integration of aubio ==

* Integrate the aubio tempo library into CLAM and the CLAM Annotator


== CLAM for video spike ==

* Integrate video processing/playback capabilities to CLAM
* Maybe through the use of Gstreamer?
