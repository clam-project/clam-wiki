= This is Totally Draft =

But come back soon. We will have a list of clam SoC ideas by the end of this week (March 10th)

== Plugin system for a dynamically extensible framework ==
more here: [[Devel/Plugins TODOs]]

* clam plugins-hosts
** Multi-platform dynamic loading of factories. 
** Hierarchical organization
** Documentation and plugin metadata (ports meta-data, etc)
* plugin creation from a clam network
** NetworkEditor as ladspa host
** NetworkEditor as vst host
** Load CLAM processings/networks as ladspa plugins

== Network Scalability (aka Subnetworks) ==
* Infrastructure to control the flow of recursive networks
* Integrate user-defined networks in the component library.
* Make it usable in NetworkEditor application.
* ...

== Scripting CLAM in Python ==


* build and use a clam network with python
* this could lead to a NetworkEditor python console with tab-completion
* use clam processings and processing-data with python. use it to visualize data, etc.
* write clam processings with python
* several approaches: Adhoc API or API export using SWIG or SIP
* network score
** Implement a simple interface that would allow a user to sequence (in time) changes to a CLAM::Network. These changes would be mainly connections between Processing objects but maybe also new configurations...
** Related to this, create a temporal control generator that generates controls every t seconds.

== Improve usability of SMSTools workflow ==

(PAU: this seems quite old. I don't understand some of this items)

(David: Not that old. But maybe the rephrase can help)

* Separate configurations and files to process
* Configurations as a presets not as data (you open an audio file and analyze it using a given preset)
* Keep intermediate (analysis) objects (not a single statefull object as now)
* Enable the user to explicitly work with those intermediate objects.
* Minimize the provided data by using object information (sampling rate on analysis, and most of the analysis parameters for synthesis)

== Convergence of SMSTools and CLAM widgets infrastructure ==
* Transformation parameter automation using time-lines (ala ardour automation)
* Metadata based widgets
* Widgets interaction (zoom)
* Network based transformations. The user should be able to define the transformation chain using NetworkEditor.

== Real-time synthesizer using SMS models ==
* a new revamped but very simple salto synthesizer.
* a db of sms samples
* processings 
** to choose samples
** interpolate
** create stream flow
** etc.

== Vowel synthesizer ==

Build a educative program that would consist on:
* synthesizing different vowels by placing a point within the [http://en.wikipedia.org/wiki/Vowel_triangle Vowel triangle],
* and, the reverse, given an input vowel from the microphone place a dot on the triangle, so the students can check their pronunciation.
This could be enhanced by:
* displaying the mouth position for the vowel,
* visualizing the spectral peaks so they can identify the effect,
* changing the pitch,
* changing the synthesized gender,
* changing the vocal track characteristics,
* extracting user's vocal track characteristics for synthesized sound.

A teacher could limit the set of vowels to the ones used for 
a particular language such as Catalan or English,
so that the students just see the relevant ones for the exercise.

== Integrate Faust with CLAM. And spectral transformations with Faust ==
probably a little out-of scope

== Enhancing chord detection algorithm for real-time use ==

TODO: Adapt scope to SoC requirements

Due to the extend it could be split a subset of the proposals.
It consist on enhancing existing 
tonal analysis algorithms so that they can work reliably on realtime
in order to be exploded by a realtime visualization that could give a
the user some insight on what he is listening.
Although the algorithm may fail to detect the exact chord being played,
visualization should be able to visualize information so that the user
could figure out what's going on.

In order to achive this, two concurrent aspects are to be addressed:
The first one is to modify and enhance existing algorithms
so that they can achieve better results working on realtime.
The second one is to find new ways of representing pitch, tonality and chord information in realtime.

Several algorithm enhancements are to be considered:
* Preprocessing
** Compute instant tunning by fasor addition on chroma peaks mapped to a semitone (done)
** Limit the time scope of the global tunning computation (done but improvements needed)
* Processing
** Find faster and more precise algorithms than the current one	
* Postprocessing
** Consider the None chord (all pitches) so that we can detect non chord segments and use it as reference for pitchness. (done)
** Symbolical analysis: Instead of correlation, analyze the pcp content using heuristic reasoning (Harte did plain filtering and some )
** Double scope for analysis: Too large windows difuminate transitions but small ones fail to detect arpeggios based chords. We could choose depending on the number of high pitches on the PCP.
** Onset alignment: Use realtime onset detection (aubio?) to 'quantize' the chord segments limits.

Enrich algorithm output so that the user may take profit of non-perfect algorithm or music that is not using recognized cords (fifths, rare chords...)
* Diffuse guessing: Minimize false positive impact to the user by computing a confidence value for each guess.
* Keeping several candidates so the user may view that he has more than one option.
* Rectified guess: Do a first realtime guess and correct it later if needed as the song goes on. 

In parallel to enhance the algorithm to realtime some views must be developed.
Some views ideas:
* KeySpace (Emilia and Jordi's) (done)
* Augmented KeySpace (not just major and minor)
* Tonnetz (pcp) (done)
* Tonnetz (pcp + chord figures)
* Chord torus (map pcp into the tonal torus space)
* Vectors in chord torus (needed to disambiguate dim chords)
* Chord ranking: all chords displayed as sorted probability bars (done)
* Chord candidates: just the ones before the first strong decay
* Realtime segment construction:
** Instant chord segment: Display segment based on the best one on each instant.
** Delayed segment: don't display a segment until we have enough information on the future to make a post processing
** Guessed segments: Until sure, display the guess
* Instrument fingering

== Integration of aubio ==

* Integrate the aubio tempo library into CLAM and the CLAM Annotator



== CLAM for video spike ==

* Integrate video processing/playback capabilities to CLAM
* Maybe through the use of Gstreamer?

== Processing class generator App/Widget ==

* Allow users to create a new Processing class by just specifying ports
and behavior of Do() in a graphical widget
* Maybe to integrate into NetworkEditor

== Qt based interfaces for CLAM Network based VST plugins ==

Enabling a Qt interface to control a CLAM Network acting as VST plugins
the same way CLAM does now for JACK and PortAudio players.

== Annotation Merger ==

Currently BOCA system does pretty well by defining merges, projections and 
attribute renaming of several annotation sources (extractors, databases,
webservices...).

BOCA merging scripts (developed in python) are distributed with the annotator.
They are useful for example to combine several extractors locally or 
an extractor and a manually annotated ground truth and compare them.
But they are hard to use for a non expert user.

It would be nice to integrate into the annotator a tool to graphically configure 
how to perform such a merge to run it locally.
The idea is that a project could have, instead of a single extractor,
a combination of descriptors sources.

== Macro manipulation of descriptors with python on Annotator ==

Make the annotation data accessible to python scripts
so that one can automate repetitive descriptors manipulation.
Some use cases:
* I want to correct an offset that a given segment annotation adds to all segments.
* I want to extend a regular beat annotation and just correct when it varies

== Enhancing Annotator Widgets ==

TODO: Adapt scope to SoC requirements

* Views for multibin frame parameters (spectrums, pcp's, chord correlation...)
* Frame level float editor
* More instant views
** Spectrum + peaks
** 
* Multiple segmentation panes
* Enhancing the usability of the segment editor
** Selection and edit actions (copy, paste..)
** Overlapping segments
** Displaying segment attributes as height
** Displaying segment attributes as color

== Flexible auralization on Annotator ==

Currently the auralization is limited to some kinds of descriptors auralization.
Currently just playing a tick on segment onset and 
float value frame level descriptors controlling the pitch of a tone.
By adding a general way to convert descriptors to control signals
they can be used to control an arbitrary synthesizer set by the user
(CLAM network? OSC/MIDI controlled synth?)
