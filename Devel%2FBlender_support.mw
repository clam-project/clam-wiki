This article explains the Blender integration on CLAM. You could find the needed Blender python scripts [http://iua-share.upf.edu/svn/clam/trunk/CLAM/plugins/spacialization/blender/ on the 'spacialization' plugin directory of the SVN].

The following scripts uses the blender objects included in the 'AudioSources' and 'AudioSinks' groups as general convention.

== Defining the Blender scene ==
=== Adapting a previous Blender scene ===
If you have an existing Blender scene, just create the 'AudioSources' and 'AudioSinks' groups and add the objects you want to use in them. Then import the script that you want to use from the following ones:

=== Creating a new Blender scene ===
If you want to start a new scene, you could import the scene_maker script and run it once. Or directly, call blender with -P from the "CLAM/plugins/spacialization/blender" path:
 blender -P scene_maker.py
It would ask how many sources and sinks you want to generate:

[[Image:Blender scene maker1.png]]

and generate UVspheres as generic models, included on the specific groups:

[[Image:Blender scene maker2.png]]

[[Image:Blender scene maker graphic.png]]

== Sending positions through OSC ==

The 'BlenderOSCSender.py' script allows to send OSC messages the source and sinks positions through OSC using '[https://iua-share.upf.edu/svn/clam/trunk/CLAM/plugins/osc/oscpython/OSC.py OSC.py] (OSC client module for python by Stefan Kersten, you have to put a copy on your home/src/liblo or have it on relative path ../../osc/oscpython).
The script could be linked to any source or sink object, on FrameChanged events or object ObjectUpdate ones. The sending OSC path is '/[http://www.jamoma.org/wiki/SpatDIFSpatialSoundDescriptionInterchangeFormat SpatDIF]/type/number/xyz', where 'type' is the type of audio object ('source' if the object exists on 'AudioSources', 'sink' if exists on 'AudioSinks') and number is the relative number within the correspondent type group. By now, the used OSC port is fixed to 7000.

=== Configuring the sender ===
You could import the BlenderOSCSender.py in your list of Text blender buffers and assign on the desired event (FrameChanged on a scene, or ObjectUpdate on a sink or a source):

[[Image:Blender link OSCSender on framechanged event.png]]

[[Image:Blender link OSCSender on ObjectUpdate event.png]]

=== Exporting the scene to CLAM network receivers ===
First at all, you will need to compile and install the OSC CLAM plugin, as MultiLibloSources are used to receive the OSC messages.
To generate a CLAM network OSC monitor for that scene, you could call the 'network_scene_exporter.py' script, which is automatically called by the scene_maker, and applied to a FrameChanged scene event. It will ask for a network filename:

[[Image:Blender scene maker filedialog network.png]]

And you will obtain a Network like this:

[[Image:Clam osc receivers for blender scene.png]]

To make it work, just run your Blender animation (alt-a), and the monitors would be updated to the objects positions, and if is called by a FrameChanged event the CLAM Network would be also show the actual frame number.

== Exporting a choreographic sequencer file ==
The blender choreographic sequencer file exporter is included on the 'choreofile_exporter.py' script, and generates the choreographic sequencer file for one sink and one source selected objects, and a sequencer monitor network (using network_scene_exporter).

First you will need to select '''just one''' sink '''and one''' source object (select with right click, add selection with shift-right click), and run the script ("alt-p" on the Text Editor using choreofile_exporter). 

The script will ask for a sequencer file name:

[[Image:Blender exporting choreoSequencer file.png]]

A Network with the same base name of the choreographic file will be created, with a choreo sequencer processing configured to read the created sequencer file at the proper controls per second (using blender animation frames per second):

[[Image:Blender generated network ChoreoSequencer.png]]

[[Image:ChoreoSequencerConfig BlenderScene.png]]

== A dummy animation ==
If you know something of Blender, maybe will found the previous scripts usefuls as templates for new Blender-CLAM integrated scenes. But if you don't know how to make animations in Blender, you still could prove this scripts just calling the demo_scene_maker script from your CLAM blender scripts path:
 blender -P demo_scene_maker.py
That would be generate the same scene and network than scene_maker, but then will add a circular trajectories on sources. So, just play the animation with "alt-a", and test the networks!
[[Image:BlenderDemoScene.png]]
